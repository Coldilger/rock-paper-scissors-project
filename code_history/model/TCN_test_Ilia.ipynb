{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# zip_path = Path('data/noaudio_ver2.zip')\n",
    "# extract_dir = zip_path.parent if zip_path.exists() else Path('data')\n",
    "\n",
    "# if not zip_path.exists():\n",
    "#     raise FileNotFoundError(f\"Zip file not found: {zip_path}\")\n",
    "\n",
    "# extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "#     z.extractall(path=extract_dir)\n",
    "#     extracted = z.namelist()\n",
    "\n",
    "# print(f\"Extracted {len(extracted)} items to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dad62c",
   "metadata": {},
   "source": [
    "# 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716ab831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_CLASSES = 3\n",
    "SEQ_LEN = 16          # Length of the frame sequence to feed the model\n",
    "FRAME_SIZE = 128      # Input size (128x128)\n",
    "FEATURE_DIM = 64      # Output of the CNN encoder\n",
    "CHANNELS = [64, 64]   # TCN layers\n",
    "KERNEL_SIZE = 3\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-3\n",
    "EPOCHS = 10\n",
    "\n",
    "# Mapping\n",
    "CLASS_MAP = {'Rock': 0, 'Paper': 1, 'Scissor': 2}\n",
    "INV_CLASS_MAP = {0: 'Rock', 1: 'Paper', 2: 'Scissor'}\n",
    "WINNING_MOVE = {\n",
    "    'Rock': 'Paper',\n",
    "    'Paper': 'Scissor',\n",
    "    'Scissor': 'Rock'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f991a9",
   "metadata": {},
   "source": [
    "# 2. The Dataset Loader (Fixed for this current file structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFramesDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, seq_len: int = 16, augment: bool = False):\n",
    "        self.root = Path(root_dir)\n",
    "        self.seq_len = seq_len\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Transforms\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((FRAME_SIZE, FRAME_SIZE)),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((FRAME_SIZE, FRAME_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self.samples = self._parse_filesystem()\n",
    "\n",
    "    def _parse_filesystem(self) -> List[Tuple[List[Path], int]]:\n",
    "        \"\"\"Parses the directory to group frames into video sequences.\"\"\"\n",
    "        samples = []\n",
    "        # Regex to capture: (VideoID)_(FrameNumber).jpg\n",
    "        # Example: 20251122_220625_720p20fps_nosound_095.jpg\n",
    "        # Group 1 is the Video ID, Group 2 is the frame index.\n",
    "        pattern = re.compile(r'(.+)_(\\d+)\\.(jpg|jpeg|png)$', re.IGNORECASE)\n",
    "\n",
    "        for cls_name, label in CLASS_MAP.items():\n",
    "            cls_dir = self.root / cls_name\n",
    "            # Handle slight naming variations (e.g. Scissor vs Scissors) if necessary\n",
    "            if not cls_dir.exists():\n",
    "                # Fallback check for plurals or lowercase if folder names vary\n",
    "                cls_dir = self.root / (cls_name + 's') \n",
    "                if not cls_dir.exists():\n",
    "                    print(f\"Warning: Directory for {cls_name} not found.\")\n",
    "                    continue\n",
    "\n",
    "            # Group frames by video ID\n",
    "            video_frames: Dict[str, List[Tuple[int, Path]]] = {}\n",
    "            \n",
    "            for img_path in cls_dir.glob('*'):\n",
    "                match = pattern.match(img_path.name)\n",
    "                if match:\n",
    "                    vid_id = match.group(1)\n",
    "                    frame_idx = int(match.group(2))\n",
    "                    if vid_id not in video_frames:\n",
    "                        video_frames[vid_id] = []\n",
    "                    video_frames[vid_id].append((frame_idx, img_path))\n",
    "\n",
    "            # Process grouped frames into sequences\n",
    "            for vid_id, frames in video_frames.items():\n",
    "                # Sort by frame index\n",
    "                frames.sort(key=lambda x: x[0])\n",
    "                paths = [p for _, p in frames]\n",
    "                \n",
    "                # We can create multiple sliding windows or just take the end\n",
    "                # Here, we take the last SEQ_LEN frames to capture the gesture formation\n",
    "                if len(paths) >= self.seq_len:\n",
    "                    # Optional: sliding window for more data\n",
    "                    # for i in range(len(paths) - self.seq_len + 1):\n",
    "                    #     samples.append((paths[i : i+self.seq_len], label))\n",
    "                    \n",
    "                    # Simple version: Take the sequence\n",
    "                    samples.append((paths[:self.seq_len], label)) \n",
    "                else:\n",
    "                    # Pad if video is too short (repeat first frame)\n",
    "                    padded = [paths[0]] * (self.seq_len - len(paths)) + paths\n",
    "                    samples.append((padded, label))\n",
    "                    \n",
    "        print(f\"Found {len(samples)} sequences.\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_paths, label = self.samples[idx]\n",
    "        images = []\n",
    "        for p in frame_paths:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            images.append(self.transform(img))\n",
    "        \n",
    "        # Stack: (Seq_Len, Channels, Height, Width)\n",
    "        seq_tensor = torch.stack(images, dim=0)\n",
    "        return seq_tensor, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee453e",
   "metadata": {},
   "source": [
    "# 3. The Model (CNN + TCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c1d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try importing TCN, handle if not installed\n",
    "try:\n",
    "    from pytorch_tcn import TCN\n",
    "except ImportError:\n",
    "    print(\"pytorch-tcn not found. Please run: pip install pytorch-tcn\")\n",
    "\n",
    "class FrameEncoder(nn.Module):\n",
    "    \"\"\"Encodes a single image frame into a feature vector.\"\"\"\n",
    "    def __init__(self, feature_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1) # Output (B, 64, 1, 1)\n",
    "        )\n",
    "        self.fc = nn.Linear(64, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch * Seq_Len, 3, H, W)\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "class GestureTCN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = FrameEncoder(feature_dim=FEATURE_DIM)\n",
    "        \n",
    "        self.tcn = TCN(\n",
    "            num_inputs=FEATURE_DIM,\n",
    "            num_channels=CHANNELS,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            dropout=DROPOUT,\n",
    "            causal=True,\n",
    "            input_shape='NCL' \n",
    "        )\n",
    "        self.classifier = nn.Linear(CHANNELS[-1], num_classes)\n",
    "\n",
    "    def forward(self, x, return_all_timesteps=False):\n",
    "        # x: (Batch, Seq_Len, 3, H, W)\n",
    "        b, t, c, h, w = x.shape\n",
    "        x_flat = x.view(b * t, c, h, w)\n",
    "        \n",
    "        features = self.encoder(x_flat)      # (B*T, Feat)\n",
    "        features = features.view(b, t, -1).permute(0, 2, 1) # (B, Feat, T) for TCN\n",
    "        \n",
    "        tcn_out = self.tcn(features)         # (B, Hidden, T)\n",
    "        \n",
    "        if return_all_timesteps:\n",
    "            # Transpose to (B, T, Hidden) so Linear layer applies to every step\n",
    "            tcn_out = tcn_out.permute(0, 2, 1) \n",
    "            return self.classifier(tcn_out)  # Returns (B, T, Num_Classes)\n",
    "        else:\n",
    "            # Standard training behavior (last step only)\n",
    "            last_out = tcn_out[:, :, -1]\n",
    "            return self.classifier(last_out) # Returns (B, Num_Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b90e75",
   "metadata": {},
   "source": [
    "# 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4b955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 sequences.\n",
      "Starting training...\n",
      "Epoch 1/10 | Loss: 1.1038 | Acc: 36.00%\n",
      "Epoch 2/10 | Loss: 1.0724 | Acc: 56.00%\n",
      "Epoch 3/10 | Loss: 1.1616 | Acc: 52.00%\n",
      "Epoch 4/10 | Loss: 1.0451 | Acc: 56.00%\n",
      "Epoch 5/10 | Loss: 0.9419 | Acc: 52.00%\n",
      "Epoch 6/10 | Loss: 0.9347 | Acc: 52.00%\n",
      "Epoch 7/10 | Loss: 1.2121 | Acc: 52.00%\n",
      "Epoch 8/10 | Loss: 0.8676 | Acc: 52.00%\n",
      "Epoch 9/10 | Loss: 0.8638 | Acc: 52.00%\n",
      "Epoch 10/10 | Loss: 0.8123 | Acc: 52.00%\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    # Update this path to your actual path!\n",
    "    # Based on your image: 'data/videos_noaudio'\n",
    "    data_path = 'data/videos_noaudio' \n",
    "    \n",
    "    dataset = VideoFramesDataset(data_path, seq_len=SEQ_LEN, augment=True)\n",
    "    \n",
    "    # Split Train/Val\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = GestureTCN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for frames, labels in train_loader:\n",
    "            frames, labels = frames.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss/len(train_loader):.4f} | Acc: {100.*correct/total:.2f}%\")\n",
    "        \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'rps_tcn_model.pth')\n",
    "    print(\"Model saved.\")\n",
    "    return model\n",
    "\n",
    "# Uncomment to run training\n",
    "model = train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c4c1d",
   "metadata": {},
   "source": [
    "# 5. The \"Winning\" Inference Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10b97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_move(model, sequence_buffer):\n",
    "    \"\"\"\n",
    "    Takes a sequence of frames (Tensor) and predicts the user's move.\n",
    "    Then returns the move that BEATS the user.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Input shape: (1, Seq_Len, 3, H, W)\n",
    "        frames = sequence_buffer.to(DEVICE)\n",
    "        logits = model(frames)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # Get the predicted class (what the user is doing)\n",
    "        confidence, pred_idx = torch.max(probs, 1)\n",
    "        user_move = INV_CLASS_MAP[pred_idx.item()]\n",
    "        \n",
    "        # Logic to beat the user\n",
    "        my_move = WINNING_MOVE[user_move]\n",
    "        \n",
    "        return user_move, my_move, confidence.item()\n",
    "\n",
    "# Example usage (simulated):\n",
    "# seq = torch.randn(1, 16, 3, 128, 128) # Replace with real camera buffer\n",
    "# user_gesture, counter_move, conf = predict_move(model, seq)\n",
    "# print(f\"User is showing {user_gesture}. I play {counter_move} to win!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fab0ce",
   "metadata": {},
   "source": [
    "# 6. Evalutaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388a3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/noaudio_ver2\n",
      "Found 52 sequences.\n",
      "Found 52 video sequences.\n",
      "Weights loaded successfully.\n",
      "\n",
      "Final Accuracy (at frame 16): 38.46%\n",
      "The model did not reach 80% accuracy.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_on_new_data(model_path, data_path):\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    \n",
    "    # 1. Create Dataset for the NEW folder\n",
    "    # We use augment=False because this is a test run\n",
    "    test_ds = VideoFramesDataset(data_path, seq_len=SEQ_LEN, augment=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "    \n",
    "    print(f\"Found {len(test_ds)} video sequences.\")\n",
    "\n",
    "    # 2. Load Model\n",
    "    model = GestureTCN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "        print(\"Weights loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model file not found. Make sure you trained it first!\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # 3. Metrics Storage\n",
    "    # We want to know: \"What is the accuracy at Frame 1? Frame 2? ... Frame 16?\"\n",
    "    correct_at_frame = [0] * SEQ_LEN\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_loader:\n",
    "            seq = seq.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            # Get output for ALL timesteps: Shape (Batch, 16, 3)\n",
    "            logits_all_steps = model(seq, return_all_timesteps=True)\n",
    "            \n",
    "            # Convert to predictions\n",
    "            preds_all_steps = logits_all_steps.argmax(dim=2) # Shape (Batch, 16)\n",
    "            \n",
    "            # Check accuracy for each timestep\n",
    "            for t in range(SEQ_LEN):\n",
    "                # How many in this batch got frame 't' correct?\n",
    "                correct_at_frame[t] += (preds_all_steps[:, t] == labels).sum().item()\n",
    "            \n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # 4. Calculate Percentages\n",
    "    accuracies = [ (c / total_samples) * 100 for c in correct_at_frame ]\n",
    "    \n",
    "    # 5. Report Results\n",
    "    final_acc = accuracies[-1]\n",
    "    print(f\"\\nFinal Accuracy (at frame {SEQ_LEN}): {final_acc:.2f}%\")\n",
    "    \n",
    "    # Find \"Early Prediction\" point (e.g., when acc > 80%)\n",
    "    early_point = next((i for i, x in enumerate(accuracies) if x > 80.0), None)\n",
    "    if early_point:\n",
    "        print(f\"The model reaches 80% accuracy at Frame {early_point + 1}!\")\n",
    "    else:\n",
    "        print(\"The model did not reach 80% accuracy.\")\n",
    "\n",
    "    # 6. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, SEQ_LEN+1), accuracies, marker='o', linestyle='-', color='b')\n",
    "    plt.axhline(y=final_acc, color='r', linestyle='--', label=f'Final: {final_acc:.1f}%')\n",
    "    plt.title(f'Early Prediction Capabilities (Tested on {data_path})')\n",
    "    plt.xlabel('Frame Number (Time)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, SEQ_LEN+1))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- RUN THE TEST ---\n",
    "# Ensure 'rps_tcn_model.pth' exists (or whatever you named your saved model)\n",
    "# Point to your NEW data folder\n",
    "evaluate_on_new_data(model_path='rps_tcn_model.pth', data_path='data/noaudio_ver2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
