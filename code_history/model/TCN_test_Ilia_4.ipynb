{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d32aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10054 items to data\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "zip_path = Path('data/noaudio_ver2.zip')\n",
    "extract_dir = zip_path.parent if zip_path.exists() else Path('data')\n",
    "\n",
    "if not zip_path.exists():\n",
    "    raise FileNotFoundError(f\"Zip file not found: {zip_path}\")\n",
    "\n",
    "extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    z.extractall(path=extract_dir)\n",
    "    extracted = z.namelist()\n",
    "\n",
    "print(f\"Extracted {len(extracted)} items to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db77939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ultralytics\n",
    "# %pip install opencv-python #for cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dad62c",
   "metadata": {},
   "source": [
    "# 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716ab831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_CLASSES = 3\n",
    "SEQ_LEN = 32          # Length of the frame sequence to feed the model\n",
    "FRAME_SIZE = 224      # Input size (224Ñ…224 as in ResNet)\n",
    "FEATURE_DIM = 64      # Output of the CNN encoder\n",
    "CHANNELS = [64, 64]   # TCN layers\n",
    "KERNEL_SIZE = 3\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-3\n",
    "EPOCHS = 10\n",
    "\n",
    "# Mapping\n",
    "CLASS_MAP = {'Rock': 0, 'Paper': 1, 'Scissor': 2}\n",
    "INV_CLASS_MAP = {0: 'Rock', 1: 'Paper', 2: 'Scissor'}\n",
    "WINNING_MOVE = {\n",
    "    'Rock': 'Paper',\n",
    "    'Paper': 'Scissor',\n",
    "    'Scissor': 'Rock'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f991a9",
   "metadata": {},
   "source": [
    "# 2. The Dataset Loader (Fixed for this current file structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFramesDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, seq_len: int = 16, augment: bool = False):\n",
    "        self.root = Path(root_dir)\n",
    "        self.seq_len = seq_len\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Transforms\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)), # Bump resolution up\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15), # Rotates hand +/- 15 degrees\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((FRAME_SIZE, FRAME_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self.samples = self._parse_filesystem()\n",
    "\n",
    "    def _parse_filesystem(self) -> List[Tuple[List[Path], int]]:\n",
    "        \"\"\"Parses the directory to group frames into video sequences.\"\"\"\n",
    "        samples = []\n",
    "        # Regex to capture: (VideoID)_(FrameNumber).jpg\n",
    "        # Example: 20251122_220625_720p20fps_nosound_095.jpg\n",
    "        # Group 1 is the Video ID, Group 2 is the frame index.\n",
    "        pattern = re.compile(r'(.+)_(\\d+)\\.(jpg|jpeg|png)$', re.IGNORECASE)\n",
    "\n",
    "        for cls_name, label in CLASS_MAP.items():\n",
    "            cls_dir = self.root / cls_name\n",
    "            # Handle slight naming variations (e.g. Scissor vs Scissors) if necessary\n",
    "            if not cls_dir.exists():\n",
    "                # Fallback check for plurals or lowercase if folder names vary\n",
    "                cls_dir = self.root / (cls_name + 's') \n",
    "                if not cls_dir.exists():\n",
    "                    print(f\"Warning: Directory for {cls_name} not found.\")\n",
    "                    continue\n",
    "\n",
    "            # Group frames by video ID\n",
    "            video_frames: Dict[str, List[Tuple[int, Path]]] = {}\n",
    "            \n",
    "            for img_path in cls_dir.glob('*'):\n",
    "                match = pattern.match(img_path.name)\n",
    "                if match:\n",
    "                    vid_id = match.group(1)\n",
    "                    frame_idx = int(match.group(2))\n",
    "                    if vid_id not in video_frames:\n",
    "                        video_frames[vid_id] = []\n",
    "                    video_frames[vid_id].append((frame_idx, img_path))\n",
    "\n",
    "            # Process grouped frames into sequences\n",
    "            for vid_id, frames in video_frames.items():\n",
    "                # Sort by frame index\n",
    "                frames.sort(key=lambda x: x[0])\n",
    "                paths = [p for _, p in frames]\n",
    "                \n",
    "                # We can create multiple sliding windows or just take the end\n",
    "                # Here, we take the last SEQ_LEN frames to capture the gesture formation\n",
    "                if len(paths) >= self.seq_len:\n",
    "                    # Optional: sliding window for more data\n",
    "                    # for i in range(len(paths) - self.seq_len + 1):\n",
    "                    #     samples.append((paths[i : i+self.seq_len], label))\n",
    "                    \n",
    "                    # Simple version: Take the sequence\n",
    "                    samples.append((paths[:self.seq_len], label)) \n",
    "                else:\n",
    "                    # Pad if video is too short (repeat first frame)\n",
    "                    padded = [paths[0]] * (self.seq_len - len(paths)) + paths\n",
    "                    samples.append((padded, label))\n",
    "                    \n",
    "        print(f\"Found {len(samples)} sequences.\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_paths, label = self.samples[idx]\n",
    "        images = []\n",
    "        for p in frame_paths:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            images.append(self.transform(img))\n",
    "        \n",
    "        # Stack: (Seq_Len, Channels, Height, Width)\n",
    "        seq_tensor = torch.stack(images, dim=0)\n",
    "        return seq_tensor, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee453e",
   "metadata": {},
   "source": [
    "# 3. The Model (CNN + TCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c1d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try importing TCN, handle if not installed\n",
    "try:\n",
    "    from pytorch_tcn import TCN\n",
    "except ImportError:\n",
    "    print(\"pytorch-tcn not found. Please run: pip install pytorch-tcn\")\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetFrameEncoder(nn.Module):\n",
    "    def __init__(self, feature_dim=64):\n",
    "        super().__init__()\n",
    "        # 1. Load a pre-trained ResNet18\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # 2. Remove the last layer (the ImageNet classifier)\n",
    "        # ResNet18's feature layer (avgpool) outputs 512 features\n",
    "        modules = list(resnet.children())[:-1] \n",
    "        self.backbone = nn.Sequential(*modules)\n",
    "        \n",
    "        # 3. Add a projection layer to get down to your TCN size (64)\n",
    "        self.proj = nn.Linear(512, feature_dim)\n",
    "        \n",
    "        # Optional: Freeze early layers to speed up training if data is small\n",
    "        # for param in list(self.backbone.children())[:6]:\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B*T, 3, 128, 128)\n",
    "        features = self.backbone(x)        # Output: (B*T, 512, 1, 1)\n",
    "        features = features.flatten(1)     # Output: (B*T, 512)\n",
    "        return self.proj(features)         # Output: (B*T, 64)\n",
    "    \n",
    "    \n",
    "class GestureTCN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetFrameEncoder(feature_dim=FEATURE_DIM) \n",
    "        \n",
    "        self.tcn = TCN(\n",
    "            num_inputs=FEATURE_DIM,\n",
    "            num_channels=CHANNELS,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            dropout=DROPOUT,\n",
    "            causal=True,\n",
    "            input_shape='NCL' \n",
    "        )\n",
    "        self.classifier = nn.Linear(CHANNELS[-1], num_classes)\n",
    "\n",
    "    def forward(self, x, return_all_timesteps=False):\n",
    "        # x: (Batch, Seq_Len, 3, H, W)\n",
    "        b, t, c, h, w = x.shape\n",
    "        x_flat = x.view(b * t, c, h, w)\n",
    "        \n",
    "        features = self.encoder(x_flat)      # (B*T, Feat)\n",
    "        features = features.view(b, t, -1).permute(0, 2, 1) # (B, Feat, T) for TCN\n",
    "        \n",
    "        tcn_out = self.tcn(features)         # (B, Hidden, T)\n",
    "        \n",
    "        if return_all_timesteps:\n",
    "            # Transpose to (B, T, Hidden) so Linear layer applies to every step\n",
    "            tcn_out = tcn_out.permute(0, 2, 1) \n",
    "            return self.classifier(tcn_out)  # Returns (B, T, Num_Classes)\n",
    "        else:\n",
    "            # Standard training behavior (last step only)\n",
    "            last_out = tcn_out[:, :, -1]\n",
    "            return self.classifier(last_out) # Returns (B, Num_Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b90e75",
   "metadata": {},
   "source": [
    "# 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4b955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61 sequences.\n",
      "Found 12 sequences.\n",
      "Starting training...\n",
      "Epoch 1/10 | Loss: 1.0539 | Acc: 42.62%\n",
      "Epoch 1/10 | Val Acc: 33.33%\n",
      "Epoch 2/10 | Loss: 0.9220 | Acc: 54.10%\n",
      "Epoch 2/10 | Val Acc: 33.33%\n",
      "Epoch 3/10 | Loss: 0.7951 | Acc: 63.93%\n",
      "Epoch 3/10 | Val Acc: 50.00%\n",
      "Epoch 4/10 | Loss: 0.5562 | Acc: 77.05%\n",
      "Epoch 4/10 | Val Acc: 83.33%\n",
      "Epoch 5/10 | Loss: 0.5000 | Acc: 77.05%\n",
      "Epoch 5/10 | Val Acc: 83.33%\n",
      "Epoch 6/10 | Loss: 0.7565 | Acc: 68.85%\n",
      "Epoch 6/10 | Val Acc: 50.00%\n",
      "Epoch 7/10 | Loss: 0.8103 | Acc: 68.85%\n",
      "Epoch 7/10 | Val Acc: 58.33%\n",
      "Epoch 8/10 | Loss: 0.6202 | Acc: 73.77%\n",
      "Epoch 8/10 | Val Acc: 50.00%\n",
      "Epoch 9/10 | Loss: 0.5433 | Acc: 78.69%\n",
      "Epoch 9/10 | Val Acc: 50.00%\n",
      "Epoch 10/10 | Loss: 0.4745 | Acc: 78.69%\n",
      "Epoch 10/10 | Val Acc: 91.67%\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. ADD THIS HELPER FUNCTION BEFORE train_model ---\n",
    "def time_weights(T, mode='sigmoid', alpha=2.0):\n",
    "    t = torch.linspace(0, 1, steps=T)\n",
    "    if mode == 'linear':\n",
    "        w = 0.1 + 0.9 * t\n",
    "    elif mode == 'sigmoid':\n",
    "        x = (t - 0.5) * alpha * 10 \n",
    "        w = torch.sigmoid(x)\n",
    "    else:\n",
    "        w = torch.ones(T)\n",
    "    # Normalize so they sum to T\n",
    "    w = w / w.sum() * T\n",
    "    return w.to(DEVICE)\n",
    "\n",
    "def train_model(data_path_train=None, data_path_val=None):\n",
    "    # Update this path to your actual path!\n",
    "    dataset_train = VideoFramesDataset(data_path_train, seq_len=SEQ_LEN, augment=True)\n",
    "    dataset_val = VideoFramesDataset(data_path_val, seq_len=SEQ_LEN, augment=True)\n",
    "    \n",
    "    train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = GestureTCN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # ### CHANGED: reduction='none' allows us to weight each frame differently\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none') \n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # ### NEW: Pre-calculate weights once\n",
    "    weights = time_weights(SEQ_LEN, mode='sigmoid', alpha=2.0)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for frames, labels in train_loader:\n",
    "            frames, labels = frames.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # ### CHANGED: Get output for ALL 16 frames, not just the last one\n",
    "            # Shape: (Batch_Size, 16, 3)\n",
    "            outputs_all_steps = model(frames, return_all_timesteps=True)\n",
    "            \n",
    "            # --- CALCULATE WEIGHTED LOSS ---\n",
    "            # 1. Reshape outputs to (Batch * 16, 3)\n",
    "            # 2. Repeat labels so every frame has a label: (Batch * 16)\n",
    "            loss_per_frame = criterion(\n",
    "                outputs_all_steps.view(-1, NUM_CLASSES), \n",
    "                labels.repeat_interleave(SEQ_LEN)\n",
    "            )\n",
    "            \n",
    "            # 3. Reshape loss back to (Batch, 16) to apply time weights\n",
    "            loss_per_frame = loss_per_frame.view(-1, SEQ_LEN)\n",
    "            \n",
    "            # 4. Multiply by our Sigmoid weights\n",
    "            weighted_loss = (loss_per_frame * weights).mean()\n",
    "            \n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += weighted_loss.item()\n",
    "            \n",
    "            # For accuracy, we still just look at the LAST frame (index -1)\n",
    "            final_output = outputs_all_steps[:, -1, :]\n",
    "            _, predicted = final_output.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss/len(train_loader):.4f} | Acc: {100.*correct/total:.2f}%\")\n",
    "        \n",
    "        # --- VALIDATION LOOP (Unchanged logic, just ensure model call is correct) ---\n",
    "        model.eval() # Don't forget this!\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad(): # Save memory\n",
    "            for frames, labels in val_loader:\n",
    "                frames, labels = frames.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                # For validation, we ONLY care about the final prediction\n",
    "                # So we use standard forward (return_all_timesteps=False)\n",
    "                outputs = model(frames, return_all_timesteps=False)\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Val Acc: {100.*val_correct/val_total:.2f}%\")\n",
    "        \n",
    "    torch.save(model.state_dict(), 'rps_tcn_model.pth')\n",
    "    print(\"Model saved.\")\n",
    "    return model\n",
    "\n",
    "# Run it\n",
    "model = train_model(data_path_train='data/final_split_dataset/train', data_path_val='data/final_split_dataset/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c4c1d",
   "metadata": {},
   "source": [
    "# 5. The \"Winning\" Inference Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10b97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_move(model, sequence_buffer):\n",
    "    \"\"\"\n",
    "    Takes a sequence of frames (Tensor) and predicts the user's move.\n",
    "    Then returns the move that BEATS the user.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Input shape: (1, Seq_Len, 3, H, W)\n",
    "        frames = sequence_buffer.to(DEVICE)\n",
    "        logits = model(frames)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # Get the predicted class (what the user is doing)\n",
    "        confidence, pred_idx = torch.max(probs, 1)\n",
    "        user_move = INV_CLASS_MAP[pred_idx.item()]\n",
    "        \n",
    "        # Logic to beat the user\n",
    "        my_move = WINNING_MOVE[user_move]\n",
    "        \n",
    "        return user_move, my_move, confidence.item()\n",
    "\n",
    "# Example usage (simulated):\n",
    "# seq = torch.randn(1, 16, 3, 128, 128) # Replace with real camera buffer\n",
    "# user_gesture, counter_move, conf = predict_move(model, seq)\n",
    "# print(f\"User is showing {user_gesture}. I play {counter_move} to win!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fab0ce",
   "metadata": {},
   "source": [
    "# 6. Evalutaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388a3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/final_split_dataset/test\n",
      "Found 15 sequences.\n",
      "Found 15 video sequences.\n",
      "Weights loaded successfully.\n",
      "\n",
      "Final Accuracy (at frame 32): 86.67%\n",
      "The model reaches 80% accuracy at Frame 27!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_on_new_data(model_path, data_path):\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    \n",
    "    # 1. Create Dataset for the NEW folder\n",
    "    # We use augment=False because this is a test run\n",
    "    test_ds = VideoFramesDataset(data_path, seq_len=SEQ_LEN, augment=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "    \n",
    "    print(f\"Found {len(test_ds)} video sequences.\")\n",
    "\n",
    "    # 2. Load Model\n",
    "    model = GestureTCN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "        print(\"Weights loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model file not found. Make sure you trained it first!\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # 3. Metrics Storage\n",
    "    # We want to know: \"What is the accuracy at Frame 1? Frame 2? ... Frame 16?\"\n",
    "    correct_at_frame = [0] * SEQ_LEN\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_loader:\n",
    "            seq = seq.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            # Get output for ALL timesteps: Shape (Batch, 16, 3)\n",
    "            logits_all_steps = model(seq, return_all_timesteps=True)\n",
    "            \n",
    "            # Convert to predictions\n",
    "            preds_all_steps = logits_all_steps.argmax(dim=2) # Shape (Batch, 16)\n",
    "            \n",
    "            # Check accuracy for each timestep\n",
    "            for t in range(SEQ_LEN):\n",
    "                # How many in this batch got frame 't' correct?\n",
    "                correct_at_frame[t] += (preds_all_steps[:, t] == labels).sum().item()\n",
    "            \n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # 4. Calculate Percentages\n",
    "    accuracies = [ (c / total_samples) * 100 for c in correct_at_frame ]\n",
    "    \n",
    "    # 5. Report Results\n",
    "    final_acc = accuracies[-1]\n",
    "    print(f\"\\nFinal Accuracy (at frame {SEQ_LEN}): {final_acc:.2f}%\")\n",
    "    \n",
    "    # Find \"Early Prediction\" point (e.g., when acc > 80%)\n",
    "    early_point = next((i for i, x in enumerate(accuracies) if x > 80.0), None)\n",
    "    if early_point:\n",
    "        print(f\"The model reaches 80% accuracy at Frame {early_point + 1}!\")\n",
    "    else:\n",
    "        print(\"The model did not reach 80% accuracy.\")\n",
    "\n",
    "    # 6. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, SEQ_LEN+1), accuracies, marker='o', linestyle='-', color='b')\n",
    "    plt.axhline(y=final_acc, color='r', linestyle='--', label=f'Final: {final_acc:.1f}%')\n",
    "    plt.title(f'Early Prediction Capabilities (Tested on {data_path})')\n",
    "    plt.xlabel('Frame Number (Time)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, SEQ_LEN+1))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- RUN THE TEST ---\n",
    "# Ensure 'rps_tcn_model.pth' exists (or whatever you named your saved model)\n",
    "# Point to your NEW data folder\n",
    "evaluate_on_new_data(model_path='rps_tcn_model.pth', data_path='data/final_split_dataset/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
